Testing bot: NonGreedyCachedEntropyWordleBot
Initializing bot (this may take a few minutes for optimized bots)...
Loading letter frequencies...
Loaded letter frequency cache with 26 letters
Loaded cache with 34,411 entropy values
Loaded cache with 44,565,000 feedback patterns
Bot initialization completed in 19.81 seconds

----------------------------------------------------------------------------------------------------
___ Testing word: 𝙊𝙑𝘼𝙏𝙀 ___

The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: 🟨🟨⬜🟨⬜
Actual Info Gain: 7.5188 bits
Posterior entropy: 6.339850002884624
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 6.339850002884624, 'actual_info_gain': 7.518810981838152, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
81 candidate words remaining.
Top 10 guesses: [('LEANT', '4.217'), ('PLANE', '4.209'), ('LEAPT', '4.159'), ('PLANT', '4.109'), ('ALANT', '4.106'), ('PLANH', '4.101'), ('ALATE', '4.080'), ('PLATE', '4.060'), ('PLANC', '4.035'), ('PENAL', '4.002')]
Top entropy choice: 𝙇𝙀𝘼𝙉𝙏 with entropy: 4.2173
Guess count low, choosing the word with highest entropy: 𝙇𝙀𝘼𝙉𝙏 with entropy: 4.2173

Guess: 𝙇𝙀𝘼𝙉𝙏, Feedback: ⬜🟨🟩⬜🟨
Actual Info Gain: 3.3399 bits
Posterior entropy: 3.0
entropy_info: {'prior_entropy': 6.339850002884624, 'posterior_entropy': 3.0, 'actual_info_gain': 3.3398500028846243, 'expected_info_gain': 4.217349936796832}
----------
The bot is making a guess...
8 candidate words remaining.
Top 10 guesses: [('BOUGE', '2.750'), ('BOUGH', '2.750'), ('EMBOG', '2.750'), ('GOUTS', '2.750'), ('GOUTY', '2.750'), ('AGUTI', '2.500'), ('AMIGO', '2.500'), ('AMONG', '2.500'), ('BOGUE', '2.500'), ('BOGUS', '2.500')]
Top entropy choice: 𝘽𝙊𝙐𝙂𝙀 with entropy: 2.7500
Using common exploratory word: 𝘽𝙊𝙐𝙂𝙃 with entropy: 2.7500

Guess: 𝘽𝙊𝙐𝙂𝙃, Feedback: ⬜🟨⬜⬜⬜
Actual Info Gain: 3.0000 bits
Posterior entropy: 0.0
entropy_info: {'prior_entropy': 3.0, 'posterior_entropy': 0.0, 'actual_info_gain': 3.0, 'expected_info_gain': 4.217349936796832}
----------
The bot is making a guess...
1 candidate words remaining.
Top 10 guesses: [('OVATE', '0.000')]
Top entropy choice: 𝙊𝙑𝘼𝙏𝙀 with entropy: 0.0000
Guess count high, choosing a candidate with the highest entropy: 𝙊𝙑𝘼𝙏𝙀 with entropy: 0.0000
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: 🟨🟨⬜🟨⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 7.519 bits, Posterior Entropy: 6.340, 
Guess: 𝙇𝙀𝘼𝙉𝙏, Feedback: ⬜🟨🟩⬜🟨, Prior Entropy: 6.340, Expected Info Gain: 4.217 bits, Actual Info Gain: 3.340 bits, Posterior Entropy: 3.000, 
Guess: 𝘽𝙊𝙐𝙂𝙃, Feedback: ⬜🟨⬜⬜⬜, Prior Entropy: 3.000, Expected Info Gain: 4.217 bits, Actual Info Gain: 3.000 bits, Posterior Entropy: 0.000, 
Guess: 𝙊𝙑𝘼𝙏𝙀, Feedback: 🟩🟩🟩🟩🟩
===================================

Time taken for 'OVATE': 2.9596 seconds

----------------------------------------------------------------------------------------------------
___ Testing word: 𝙂𝙐𝘼𝙉𝙊 ___

The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟨⬜⬜⬜
Actual Info Gain: 4.3449 bits
Posterior entropy: 9.513727595952437
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 9.513727595952437, 'actual_info_gain': 4.34493338877034, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
731 candidate words remaining.
Top 10 guesses: [('COLIN', '5.613'), ('LIANA', '5.503'), ('ALOIN', '5.496'), ('PILON', '5.458'), ('PINOL', '5.439'), ('DINLO', '5.430'), ('LOGIN', '5.388'), ('NICOL', '5.363'), ('NMOLI', '5.336'), ('ULMIN', '5.322')]
Top entropy choice: 𝘾𝙊𝙇𝙄𝙉 with entropy: 5.6132
Guess count low, choosing the word with highest entropy: 𝘾𝙊𝙇𝙄𝙉 with entropy: 5.6132

Guess: 𝘾𝙊𝙇𝙄𝙉, Feedback: ⬜🟨⬜⬜🟨
Actual Info Gain: 6.7064 bits
Posterior entropy: 2.807354922057604
entropy_info: {'prior_entropy': 9.513727595952437, 'posterior_entropy': 2.807354922057604, 'actual_info_gain': 6.706372673894833, 'expected_info_gain': 5.613155296118865}
----------
The bot is making a guess...
7 candidate words remaining.
Top 10 guesses: [('ABOMA', '2.807'), ('AGLOO', '2.807'), ('AGOGO', '2.807'), ('AGRUM', '2.807'), ('AIMAG', '2.807'), ('ALGUM', '2.807'), ('ALMUG', '2.807'), ('ALONG', '2.807'), ('AMBOS', '2.807'), ('AMIGO', '2.807')]
Top entropy choice: 𝘼𝘽𝙊𝙈𝘼 with entropy: 2.8074
Using common exploratory word: 𝘼𝙇𝙊𝙉𝙂 with entropy: 2.8074

Guess: 𝘼𝙇𝙊𝙉𝙂, Feedback: 🟨⬜🟨🟩🟨
Actual Info Gain: 2.8074 bits
Posterior entropy: 0.0
entropy_info: {'prior_entropy': 2.807354922057604, 'posterior_entropy': 0.0, 'actual_info_gain': 2.807354922057604, 'expected_info_gain': 5.613155296118865}
----------
The bot is making a guess...
1 candidate words remaining.
Top 10 guesses: [('GUANO', '0.000')]
Top entropy choice: 𝙂𝙐𝘼𝙉𝙊 with entropy: 0.0000
Guess count high, choosing a candidate with the highest entropy: 𝙂𝙐𝘼𝙉𝙊 with entropy: 0.0000
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟨⬜⬜⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 4.345 bits, Posterior Entropy: 9.514, 
Guess: 𝘾𝙊𝙇𝙄𝙉, Feedback: ⬜🟨⬜⬜🟨, Prior Entropy: 9.514, Expected Info Gain: 5.613 bits, Actual Info Gain: 6.706 bits, Posterior Entropy: 2.807, 
Guess: 𝘼𝙇𝙊𝙉𝙂, Feedback: 🟨⬜🟨🟩🟨, Prior Entropy: 2.807, Expected Info Gain: 5.613 bits, Actual Info Gain: 2.807 bits, Posterior Entropy: 0.000, 
Guess: 𝙂𝙐𝘼𝙉𝙊, Feedback: 🟩🟩🟩🟩🟩
===================================

Time taken for 'GUANO': 24.3122 seconds

----------------------------------------------------------------------------------------------------
___ Testing word: 𝙇𝙊𝙏𝙏𝘼 ___

The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: 🟨🟨⬜⬜⬜
Actual Info Gain: 6.6298 bits
Posterior entropy: 7.22881869049588
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 7.22881869049588, 'actual_info_gain': 6.629842294226896, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
150 candidate words remaining.
Top 10 guesses: [('LIANA', '4.828'), ('ALOIN', '4.728'), ('COALA', '4.702'), ('NITTO', '4.661'), ('PLOIT', '4.652'), ('POINT', '4.636'), ('COLIN', '4.634'), ('CLINT', '4.625'), ('PITOT', '4.606'), ('NICOL', '4.578')]
Top entropy choice: 𝙇𝙄𝘼𝙉𝘼 with entropy: 4.8283
Guess count low, choosing the word with highest entropy: 𝙇𝙄𝘼𝙉𝘼 with entropy: 4.8283

Guess: 𝙇𝙄𝘼𝙉𝘼, Feedback: 🟩⬜⬜⬜🟩
Actual Info Gain: 6.2288 bits
Posterior entropy: 1.0
entropy_info: {'prior_entropy': 7.22881869049588, 'posterior_entropy': 1.0, 'actual_info_gain': 6.22881869049588, 'expected_info_gain': 4.8283043129740655}
----------
The bot is making a guess...
2 candidate words remaining.
Top 10 guesses: [('LOTTA', '1.000'), ('LYTTA', '1.000')]
Top entropy choice: 𝙇𝙊𝙏𝙏𝘼 with entropy: 1.0000
Few candidates left, going through them all to pick a common word...
Using common word: 𝙇𝙊𝙏𝙏𝘼 with entropy: 1.0000
You won! Amount of guesses: 3

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: 🟨🟨⬜⬜⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 6.630 bits, Posterior Entropy: 7.229, 
Guess: 𝙇𝙄𝘼𝙉𝘼, Feedback: 🟩⬜⬜⬜🟩, Prior Entropy: 7.229, Expected Info Gain: 4.828 bits, Actual Info Gain: 6.229 bits, Posterior Entropy: 1.000, 
Guess: 𝙇𝙊𝙏𝙏𝘼, Feedback: 🟩🟩🟩🟩🟩
===================================

Time taken for 'LOTTA': 5.5694 seconds

----------------------------------------------------------------------------------------------------
___ Testing word: 𝙂𝙐𝙄𝘿𝙊 ___

The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜⬜⬜⬜⬜
Actual Info Gain: 3.8615 bits
Posterior entropy: 9.997179480937621
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 9.997179480937621, 'actual_info_gain': 3.8614815037851553, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
1022 candidate words remaining.
Top 10 guesses: [('COLIN', '5.938'), ('NOILY', '5.864'), ('DINLO', '5.841'), ('PIONY', '5.791'), ('LINGO', '5.749'), ('PILON', '5.742'), ('PINOL', '5.704'), ('LOGIN', '5.699'), ('DOILY', '5.681'), ('NICOL', '5.680')]
Top entropy choice: 𝘾𝙊𝙇𝙄𝙉 with entropy: 5.9379
Guess count low, choosing the word with highest entropy: 𝘾𝙊𝙇𝙄𝙉 with entropy: 5.9379

Guess: 𝘾𝙊𝙇𝙄𝙉, Feedback: ⬜🟨⬜🟨⬜
Actual Info Gain: 5.2423 bits
Posterior entropy: 4.754887502163468
entropy_info: {'prior_entropy': 9.997179480937621, 'posterior_entropy': 4.754887502163468, 'actual_info_gain': 5.242291978774153, 'expected_info_gain': 5.937896650379372}
----------
The bot is making a guess...
27 candidate words remaining.
Top 10 guesses: [('DIMBO', '4.060'), ('DUMBO', '3.958'), ('BUMPH', '3.940'), ('HUMID', '3.884'), ('KIMBO', '3.764'), ('DUBBO', '3.750'), ('BINDI', '3.732'), ('BEMUD', '3.731'), ('MIGOD', '3.723'), ('BUNDH', '3.723')]
Top entropy choice: 𝘿𝙄𝙈𝘽𝙊 with entropy: 4.0603
Using common exploratory word: 𝘿𝙐𝙈𝘽𝙊 with entropy: 3.9582

Guess: 𝘿𝙐𝙈𝘽𝙊, Feedback: 🟨🟩⬜⬜🟩
Actual Info Gain: 4.7549 bits
Posterior entropy: 0.0
entropy_info: {'prior_entropy': 4.754887502163468, 'posterior_entropy': 0.0, 'actual_info_gain': 4.754887502163468, 'expected_info_gain': 5.937896650379372}
----------
The bot is making a guess...
1 candidate words remaining.
Top 10 guesses: [('GUIDO', '0.000')]
Top entropy choice: 𝙂𝙐𝙄𝘿𝙊 with entropy: 0.0000
Guess count high, choosing a candidate with the highest entropy: 𝙂𝙐𝙄𝘿𝙊 with entropy: 0.0000
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜⬜⬜⬜⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 3.861 bits, Posterior Entropy: 9.997, 
Guess: 𝘾𝙊𝙇𝙄𝙉, Feedback: ⬜🟨⬜🟨⬜, Prior Entropy: 9.997, Expected Info Gain: 5.938 bits, Actual Info Gain: 5.242 bits, Posterior Entropy: 4.755, 
Guess: 𝘿𝙐𝙈𝘽𝙊, Feedback: 🟨🟩⬜⬜🟩, Prior Entropy: 4.755, Expected Info Gain: 5.938 bits, Actual Info Gain: 4.755 bits, Posterior Entropy: 0.000, 
Guess: 𝙂𝙐𝙄𝘿𝙊, Feedback: 🟩🟩🟩🟩🟩
===================================

Time taken for 'GUIDO': 31.9864 seconds

----------------------------------------------------------------------------------------------------
___ Testing word: 𝙈𝙊𝙎𝙎𝙔 ___

The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜⬜⬜⬜🟨
Actual Info Gain: 5.4967 bits
Posterior entropy: 8.361943773735241
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 8.361943773735241, 'actual_info_gain': 5.496717210987535, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
329 candidate words remaining.
Top 10 guesses: [('SOILY', '5.323'), ('NOILY', '5.322'), ('PIONY', '5.294'), ('PINOL', '5.237'), ('PILON', '5.236'), ('SHIOK', '5.193'), ('CHOIL', '5.184'), ('SPOIL', '5.183'), ('SHILY', '5.157'), ('SOULY', '5.152')]
Top entropy choice: 𝙎𝙊𝙄𝙇𝙔 with entropy: 5.3226
Guess count low, choosing the word with highest entropy: 𝙎𝙊𝙄𝙇𝙔 with entropy: 5.3226

Guess: 𝙎𝙊𝙄𝙇𝙔, Feedback: 🟨🟩⬜⬜🟩
Actual Info Gain: 4.5546 bits
Posterior entropy: 3.807354922057604
entropy_info: {'prior_entropy': 8.361943773735241, 'posterior_entropy': 3.807354922057604, 'actual_info_gain': 4.554588851677638, 'expected_info_gain': 5.322573042242079}
----------
The bot is making a guess...
14 candidate words remaining.
Top 10 guesses: [('PLUMB', '3.039'), ('PUNIM', '2.950'), ('UMPED', '2.896'), ('PUBCO', '2.842'), ('PUBIC', '2.842'), ('PUBSY', '2.842'), ('PLUMP', '2.835'), ('PUMPS', '2.835'), ('PUMPY', '2.835'), ('POYOU', '2.807')]
Top entropy choice: 𝙋𝙇𝙐𝙈𝘽 with entropy: 3.0391
Using common exploratory word: 𝙋𝙇𝙐𝙈𝘽 with entropy: 3.0391

Guess: 𝙋𝙇𝙐𝙈𝘽, Feedback: ⬜⬜⬜🟨⬜
Actual Info Gain: 3.8074 bits
Posterior entropy: 0.0
entropy_info: {'prior_entropy': 3.807354922057604, 'posterior_entropy': 0.0, 'actual_info_gain': 3.807354922057604, 'expected_info_gain': 5.322573042242079}
----------
The bot is making a guess...
1 candidate words remaining.
Top 10 guesses: [('MOSSY', '0.000')]
Top entropy choice: 𝙈𝙊𝙎𝙎𝙔 with entropy: 0.0000
Guess count high, choosing a candidate with the highest entropy: 𝙈𝙊𝙎𝙎𝙔 with entropy: 0.0000
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜⬜⬜⬜🟨, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 5.497 bits, Posterior Entropy: 8.362, 
Guess: 𝙎𝙊𝙄𝙇𝙔, Feedback: 🟨🟩⬜⬜🟩, Prior Entropy: 8.362, Expected Info Gain: 5.323 bits, Actual Info Gain: 4.555 bits, Posterior Entropy: 3.807, 
Guess: 𝙋𝙇𝙐𝙈𝘽, Feedback: ⬜⬜⬜🟨⬜, Prior Entropy: 3.807, Expected Info Gain: 5.323 bits, Actual Info Gain: 3.807 bits, Posterior Entropy: 0.000, 
Guess: 𝙈𝙊𝙎𝙎𝙔, Feedback: 🟩🟩🟩🟩🟩
===================================

Time taken for 'MOSSY': 10.9622 seconds

----------------------------------------------------------------------------------------------------
___ Testing word: 𝙀𝙉𝙏𝙀𝙍 ___

The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: 🟨⬜🟨🟩⬜
Actual Info Gain: 8.3992 bits
Posterior entropy: 5.459431618637297
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 5.459431618637297, 'actual_info_gain': 8.399229366085478, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
44 candidate words remaining.
Top 10 guesses: [('NOTUM', '3.624'), ('MOULT', '3.571'), ('MOUNT', '3.570'), ('MOHUR', '3.492'), ('POULT', '3.455'), ('PITOT', '3.441'), ('OUBIT', '3.433'), ('MUTON', '3.424'), ('POTIN', '3.410'), ('HUMOR', '3.410')]
Top entropy choice: 𝙉𝙊𝙏𝙐𝙈 with entropy: 3.6238
Guess count low, choosing the word with highest entropy: 𝙉𝙊𝙏𝙐𝙈 with entropy: 3.6238

Guess: 𝙉𝙊𝙏𝙐𝙈, Feedback: 🟨⬜🟩⬜⬜
Actual Info Gain: 4.4594 bits
Posterior entropy: 1.0
entropy_info: {'prior_entropy': 5.459431618637297, 'posterior_entropy': 1.0, 'actual_info_gain': 4.459431618637297, 'expected_info_gain': 3.6237917102166546}
----------
The bot is making a guess...
2 candidate words remaining.
Top 10 guesses: [('ENTER', '1.000'), ('INTER', '1.000')]
Top entropy choice: 𝙀𝙉𝙏𝙀𝙍 with entropy: 1.0000
Few candidates left, going through them all to pick a common word...
Using common word: 𝙀𝙉𝙏𝙀𝙍 with entropy: 1.0000
You won! Amount of guesses: 3

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: 🟨⬜🟨🟩⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 8.399 bits, Posterior Entropy: 5.459, 
Guess: 𝙉𝙊𝙏𝙐𝙈, Feedback: 🟨⬜🟩⬜⬜, Prior Entropy: 5.459, Expected Info Gain: 3.624 bits, Actual Info Gain: 4.459 bits, Posterior Entropy: 1.000, 
Guess: 𝙀𝙉𝙏𝙀𝙍, Feedback: 🟩🟩🟩🟩🟩
===================================

Time taken for 'ENTER': 1.2863 seconds

----------------------------------------------------------------------------------------------------
___ Testing word: 𝙑𝙊𝙇𝙏𝘼 ___

The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: 🟨🟨⬜⬜⬜
Actual Info Gain: 6.6298 bits
Posterior entropy: 7.22881869049588
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 7.22881869049588, 'actual_info_gain': 6.629842294226896, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
150 candidate words remaining.
Top 10 guesses: [('LIANA', '4.828'), ('ALOIN', '4.728'), ('COALA', '4.702'), ('NITTO', '4.661'), ('PLOIT', '4.652'), ('POINT', '4.636'), ('COLIN', '4.634'), ('CLINT', '4.625'), ('PITOT', '4.606'), ('NICOL', '4.578')]
Top entropy choice: 𝙇𝙄𝘼𝙉𝘼 with entropy: 4.8283
Guess count low, choosing the word with highest entropy: 𝙇𝙄𝘼𝙉𝘼 with entropy: 4.8283

Guess: 𝙇𝙄𝘼𝙉𝘼, Feedback: 🟨⬜⬜⬜🟩
Actual Info Gain: 6.2288 bits
Posterior entropy: 1.0
entropy_info: {'prior_entropy': 7.22881869049588, 'posterior_entropy': 1.0, 'actual_info_gain': 6.22881869049588, 'expected_info_gain': 4.8283043129740655}
----------
The bot is making a guess...
2 candidate words remaining.
Top 10 guesses: [('FLOTA', '1.000'), ('VOLTA', '1.000')]
Top entropy choice: 𝙁𝙇𝙊𝙏𝘼 with entropy: 1.0000
Few candidates left, going through them all to pick a common word...
Using common word: 𝙑𝙊𝙇𝙏𝘼 with entropy: 1.0000
You won! Amount of guesses: 3

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: 🟨🟨⬜⬜⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 6.630 bits, Posterior Entropy: 7.229, 
Guess: 𝙇𝙄𝘼𝙉𝘼, Feedback: 🟨⬜⬜⬜🟩, Prior Entropy: 7.229, Expected Info Gain: 4.828 bits, Actual Info Gain: 6.229 bits, Posterior Entropy: 1.000, 
Guess: 𝙑𝙊𝙇𝙏𝘼, Feedback: 🟩🟩🟩🟩🟩
===================================

Time taken for 'VOLTA': 4.6212 seconds

----------------------------------------------------------------------------------------------------
___ Testing word: 𝙈𝙊𝙍𝙀𝙇 ___

The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜⬜🟩🟩⬜
Actual Info Gain: 8.0513 bits
Posterior entropy: 5.807354922057604
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 5.807354922057604, 'actual_info_gain': 8.051306062665173, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
56 candidate words remaining.
Top 10 guesses: [('MOULD', '3.981'), ('DUOMI', '3.974'), ('DOMIC', '3.884'), ('DOLCI', '3.836'), ('COULD', '3.823'), ('DUMBO', '3.814'), ('DOILY', '3.778'), ('DEMOI', '3.766'), ('LUCID', '3.759'), ('CLOUD', '3.745')]
Top entropy choice: 𝙈𝙊𝙐𝙇𝘿 with entropy: 3.9805
Guess count low, choosing the word with highest entropy: 𝙈𝙊𝙐𝙇𝘿 with entropy: 3.9805

Guess: 𝙈𝙊𝙐𝙇𝘿, Feedback: 🟩🟩⬜🟨⬜
Actual Info Gain: 5.8074 bits
Posterior entropy: 0.0
entropy_info: {'prior_entropy': 5.807354922057604, 'posterior_entropy': 0.0, 'actual_info_gain': 5.807354922057604, 'expected_info_gain': 3.980502019846924}
----------
The bot is making a guess...
1 candidate words remaining.
Top 10 guesses: [('MOREL', '0.000')]
Top entropy choice: 𝙈𝙊𝙍𝙀𝙇 with entropy: 0.0000
Few candidates left, going through them all to pick a common word...
Using common word: 𝙈𝙊𝙍𝙀𝙇 with entropy: 0.0000
You won! Amount of guesses: 3

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜⬜🟩🟩⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 8.051 bits, Posterior Entropy: 5.807, 
Guess: 𝙈𝙊𝙐𝙇𝘿, Feedback: 🟩🟩⬜🟨⬜, Prior Entropy: 5.807, Expected Info Gain: 3.981 bits, Actual Info Gain: 5.807 bits, Posterior Entropy: 0.000, 
Guess: 𝙈𝙊𝙍𝙀𝙇, Feedback: 🟩🟩🟩🟩🟩
===================================

Time taken for 'MOREL': 1.8570 seconds

----------------------------------------------------------------------------------------------------
___ Testing word: 𝙅𝙐𝙍𝙊𝙍 ___

The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜⬜🟩⬜⬜
Actual Info Gain: 6.7926 bits
Posterior entropy: 7.066089190457772
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 7.066089190457772, 'actual_info_gain': 6.792571794265005, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
134 candidate words remaining.
Top 10 guesses: [('GOYIM', '4.762'), ('DINGO', '4.689'), ('MODIN', '4.675'), ('DINLO', '4.673'), ('MUGIL', '4.672'), ('MIGOD', '4.666'), ('LINGO', '4.633'), ('MUCID', '4.620'), ('LOGIN', '4.605'), ('YOGIN', '4.602')]
Top entropy choice: 𝙂𝙊𝙔𝙄𝙈 with entropy: 4.7622
Guess count low, choosing the word with highest entropy: 𝙂𝙊𝙔𝙄𝙈 with entropy: 4.7622

Guess: 𝙂𝙊𝙔𝙄𝙈, Feedback: ⬜🟨⬜⬜⬜
Actual Info Gain: 4.4811 bits
Posterior entropy: 2.584962500721156
entropy_info: {'prior_entropy': 7.066089190457772, 'posterior_entropy': 2.584962500721156, 'actual_info_gain': 4.481126689736616, 'expected_info_gain': 4.762246063934135}
----------
The bot is making a guess...
6 candidate words remaining.
Top 10 guesses: [('FARRO', '2.585'), ('FLOOD', '2.585'), ('FLOOR', '2.585'), ('CHOOF', '2.252'), ('DOJOS', '2.252'), ('FJORD', '2.252'), ('FORDO', '2.252'), ('JOCKO', '2.252'), ('JOCOS', '2.252'), ('ALOOF', '2.252')]
Top entropy choice: 𝙁𝘼𝙍𝙍𝙊 with entropy: 2.5850
Using common exploratory word: 𝙁𝙇𝙊𝙊𝘿 with entropy: 2.5850

Guess: 𝙁𝙇𝙊𝙊𝘿, Feedback: ⬜⬜⬜🟩⬜
Actual Info Gain: 2.5850 bits
Posterior entropy: 0.0
entropy_info: {'prior_entropy': 2.584962500721156, 'posterior_entropy': 0.0, 'actual_info_gain': 2.584962500721156, 'expected_info_gain': 4.762246063934135}
----------
The bot is making a guess...
1 candidate words remaining.
Top 10 guesses: [('JUROR', '0.000')]
Top entropy choice: 𝙅𝙐𝙍𝙊𝙍 with entropy: 0.0000
Guess count high, choosing a candidate with the highest entropy: 𝙅𝙐𝙍𝙊𝙍 with entropy: 0.0000
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜⬜🟩⬜⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 6.793 bits, Posterior Entropy: 7.066, 
Guess: 𝙂𝙊𝙔𝙄𝙈, Feedback: ⬜🟨⬜⬜⬜, Prior Entropy: 7.066, Expected Info Gain: 4.762 bits, Actual Info Gain: 4.481 bits, Posterior Entropy: 2.585, 
Guess: 𝙁𝙇𝙊𝙊𝘿, Feedback: ⬜⬜⬜🟩⬜, Prior Entropy: 2.585, Expected Info Gain: 4.762 bits, Actual Info Gain: 2.585 bits, Posterior Entropy: 0.000, 
Guess: 𝙅𝙐𝙍𝙊𝙍, Feedback: 🟩🟩🟩🟩🟩
===================================

Time taken for 'JUROR': 4.2080 seconds

----------------------------------------------------------------------------------------------------
___ Testing word: 𝙄𝙉𝙏𝙀𝙇 ___

The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: 🟨⬜⬜🟩⬜
Actual Info Gain: 7.3509 bits
Posterior entropy: 6.507794640198696
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 6.507794640198696, 'actual_info_gain': 7.35086634452408, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
91 candidate words remaining.
Top 10 guesses: [('DOILT', '4.430'), ('LOUND', '4.420'), ('MOULD', '4.396'), ('NOULD', '4.383'), ('DOLCI', '4.351'), ('MOULT', '4.308'), ('BOULT', '4.293'), ('MOUND', '4.284'), ('DONUT', '4.283'), ('LOTIC', '4.267')]
Top entropy choice: 𝘿𝙊𝙄𝙇𝙏 with entropy: 4.4301
Guess count low, choosing the word with highest entropy: 𝘿𝙊𝙄𝙇𝙏 with entropy: 4.4301

Guess: 𝘿𝙊𝙄𝙇𝙏, Feedback: ⬜⬜🟨🟨🟨
Actual Info Gain: 5.5078 bits
Posterior entropy: 1.0
entropy_info: {'prior_entropy': 6.507794640198696, 'posterior_entropy': 1.0, 'actual_info_gain': 5.507794640198696, 'expected_info_gain': 4.430062736390321}
----------
The bot is making a guess...
2 candidate words remaining.
Top 10 guesses: [('INTEL', '1.000'), ('LITEM', '1.000')]
Top entropy choice: 𝙄𝙉𝙏𝙀𝙇 with entropy: 1.0000
Few candidates left, going through them all to pick a common word...
Using common word: 𝙄𝙉𝙏𝙀𝙇 with entropy: 1.0000
You won! Amount of guesses: 3

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: 🟨⬜⬜🟩⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 7.351 bits, Posterior Entropy: 6.508, 
Guess: 𝘿𝙊𝙄𝙇𝙏, Feedback: ⬜⬜🟨🟨🟨, Prior Entropy: 6.508, Expected Info Gain: 4.430 bits, Actual Info Gain: 5.508 bits, Posterior Entropy: 1.000, 
Guess: 𝙄𝙉𝙏𝙀𝙇, Feedback: 🟩🟩🟩🟩🟩
===================================

Time taken for 'INTEL': 2.9005 seconds

Total time for 3000 words: 110.48 seconds
Average time per word: 0.0302 seconds
Testing bot class: NonGreedyCachedEntropyWordleBot complete.
