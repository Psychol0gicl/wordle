Testing bot: WordleBot
___ Testing word: 𝘽𝘼𝙍𝙊𝙉 ___

First Starting word: 'TARES' (Best starting word for catching common words)
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜⬜
entropy_info: None
----------
The bot originally chose: MARDY 
The top ten guesses and scores: [('MARDY', 382), ('BARMY', 379), ('YARCO', 377), ('CARDY', 376), ('DARCY', 376), ('CARBY', 373), ('CAROM', 372), ('MARLY', 372), ('BARDY', 371), ('MARVY', 369)]
The bot finally chose: DARCY 
Guess: 𝘿𝘼𝙍𝘾𝙔, Feedback: ⬜🟩🟩⬜⬜
entropy_info: None
----------
The bot originally chose: MARGO 
The top ten guesses and scores: [('MARGO', 184), ('PARMO', 180), ('MARON', 179), ('MARIL', 178), ('GARUM', 174), ('HARIM', 174), ('MAROR', 172), ('GARAM', 170), ('LARUM', 170), ('MARGA', 170)]
The bot finally chose: MARGO 
Guess: 𝙈𝘼𝙍𝙂𝙊, Feedback: ⬜🟩🟩⬜🟨
entropy_info: None
----------
The bot originally chose: BARON 
The top ten guesses and scores: [('BARON', 8), ('PAROL', 8)]
The bot finally chose: BARON 
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜⬜
Guess: 𝘿𝘼𝙍𝘾𝙔, Feedback: ⬜🟩🟩⬜⬜
Guess: 𝙈𝘼𝙍𝙂𝙊, Feedback: ⬜🟩🟩⬜🟨
Guess: 𝘽𝘼𝙍𝙊𝙉, Feedback: 🟩🟩🟩🟩🟩
===================================

Testing bot class: WordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: EntropyWordleBot
___ Testing word: 𝘽𝘼𝙍𝙊𝙉 ___


The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜⬜
Actual Info Gain: 6.9760 bits
Posterior entropy: 6.882643049361842
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 6.882643049361842, 'actual_info_gain': 6.976017935360935, 'expected_info_gain': 6.15937645579268}
----------

The bot is making a guess...
Initial guess by the bot: MARAY with entropy: 3.0671
Bot chose: MARIA with entropy: 3.0243
Top ten guesses: [('MARAY', 3.0670663590717395), ('MARIA', 3.024320009766213), ('MARDY', 2.9238855716298238), ('CARDY', 2.8629027594517984), ('DARCY', 2.832886107371227), ('MARGA', 2.8297569507817197), ('MARAL', 2.7971077481399016), ('CAROM', 2.7756421398035815), ('MARAN', 2.7738889259167983), ('MARRA', 2.772453849556361)]

Guess: 𝙈𝘼𝙍𝙄𝘼, Feedback: ⬜🟩🟩⬜⬜
Actual Info Gain: 1.2679 bits
Posterior entropy: 5.614709844115208
entropy_info: {'prior_entropy': 6.882643049361842, 'posterior_entropy': 5.614709844115208, 'actual_info_gain': 1.2679332052466332, 'expected_info_gain': 3.024320009766213}
----------

The bot is making a guess...
Initial guess by the bot: CARBO with entropy: 3.4428
Bot chose: CAROL with entropy: 3.1451
Top ten guesses: [('CARBO', 3.44282444845051), ('CAROB', 3.286671704483097), ('CARBY', 3.2777844496306727), ('BARDO', 3.235576632173068), ('CAROL', 3.145063808674673), ('CARDY', 3.073966613325062), ('BARDY', 3.061660154410613), ('DARCY', 3.0177444194033582), ('CARON', 2.9879624409432055), ('NARCO', 2.9771598896578833)]

Guess: 𝘾𝘼𝙍𝙊𝙇, Feedback: ⬜🟩🟩🟩⬜
Actual Info Gain: 4.0297 bits
Posterior entropy: 1.584962500721156
entropy_info: {'prior_entropy': 5.614709844115208, 'posterior_entropy': 1.584962500721156, 'actual_info_gain': 4.029747343394052, 'expected_info_gain': 3.145063808674673}
----------

The bot is making a guess...
Initial guess by the bot: BARON with entropy: 1.5850
Bot chose: BARON with entropy: 1.5850
Top ten guesses: [('BARON', 1.584962500721156), ('NAROD', 1.584962500721156), ('KAROO', 0.9182958340544896)]
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 6.976 bits, Posterior Entropy: 6.883, 
Guess: 𝙈𝘼𝙍𝙄𝘼, Feedback: ⬜🟩🟩⬜⬜, Prior Entropy: 6.883, Expected Info Gain: 3.024 bits, Actual Info Gain: 1.268 bits, Posterior Entropy: 5.615, 
Guess: 𝘾𝘼𝙍𝙊𝙇, Feedback: ⬜🟩🟩🟩⬜, Prior Entropy: 5.615, Expected Info Gain: 3.145 bits, Actual Info Gain: 4.030 bits, Posterior Entropy: 1.585, 
Guess: 𝘽𝘼𝙍𝙊𝙉, Feedback: 🟩🟩🟩🟩🟩
===================================

Testing bot class: EntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: FastEntropyWordleBot
___ Testing word: 𝘽𝘼𝙍𝙊𝙉 ___


The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜⬜
Actual Info Gain: 6.9760 bits
Posterior entropy: 6.882643049361842
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 6.882643049361842, 'actual_info_gain': 6.976017935360935, 'expected_info_gain': 6.15937645579268}
----------

The bot is making a guess...
Initial guess by the bot: MARAY with entropy: 3.0671
Bot chose: MARIA with entropy: 3.0243
Top ten guesses: [('MARAY', 3.0670663590717395), ('MARIA', 3.024320009766213), ('MARDY', 2.9238855716298238), ('CARDY', 2.8629027594517984), ('DARCY', 2.832886107371227), ('MARGA', 2.8297569507817197), ('MARAL', 2.7971077481399016), ('CAROM', 2.7756421398035815), ('MARAN', 2.7738889259167983), ('MARRA', 2.772453849556361)]

Guess: 𝙈𝘼𝙍𝙄𝘼, Feedback: ⬜🟩🟩⬜⬜
Actual Info Gain: 1.2679 bits
Posterior entropy: 5.614709844115208
entropy_info: {'prior_entropy': 6.882643049361842, 'posterior_entropy': 5.614709844115208, 'actual_info_gain': 1.2679332052466332, 'expected_info_gain': 3.024320009766213}
----------

The bot is making a guess...
Initial guess by the bot: CARBO with entropy: 3.4428
Bot chose: CAROL with entropy: 3.1451
Top ten guesses: [('CARBO', 3.44282444845051), ('CAROB', 3.286671704483097), ('CARBY', 3.2777844496306727), ('BARDO', 3.235576632173068), ('CAROL', 3.145063808674673), ('CARDY', 3.073966613325062), ('BARDY', 3.061660154410613), ('DARCY', 3.0177444194033582), ('CARON', 2.9879624409432055), ('NARCO', 2.9771598896578833)]

Guess: 𝘾𝘼𝙍𝙊𝙇, Feedback: ⬜🟩🟩🟩⬜
Actual Info Gain: 4.0297 bits
Posterior entropy: 1.584962500721156
entropy_info: {'prior_entropy': 5.614709844115208, 'posterior_entropy': 1.584962500721156, 'actual_info_gain': 4.029747343394052, 'expected_info_gain': 3.145063808674673}
----------

The bot is making a guess...
Initial guess by the bot: BARON with entropy: 1.5850
Bot chose: BARON with entropy: 1.5850
Top ten guesses: [('BARON', 1.584962500721156), ('NAROD', 1.584962500721156), ('KAROO', 0.9182958340544896)]
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 6.976 bits, Posterior Entropy: 6.883, 
Guess: 𝙈𝘼𝙍𝙄𝘼, Feedback: ⬜🟩🟩⬜⬜, Prior Entropy: 6.883, Expected Info Gain: 3.024 bits, Actual Info Gain: 1.268 bits, Posterior Entropy: 5.615, 
Guess: 𝘾𝘼𝙍𝙊𝙇, Feedback: ⬜🟩🟩🟩⬜, Prior Entropy: 5.615, Expected Info Gain: 3.145 bits, Actual Info Gain: 4.030 bits, Posterior Entropy: 1.585, 
Guess: 𝘽𝘼𝙍𝙊𝙉, Feedback: 🟩🟩🟩🟩🟩
===================================

Testing bot class: FastEntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: CachedEntropyWordleBot
___ Testing word: 𝘽𝘼𝙍𝙊𝙉 ___

Loading letter frequencies...
Loaded letter frequency cache with 26 letters
The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜⬜
Actual Info Gain: 6.9760 bits
Posterior entropy: 6.882643049361842
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 6.882643049361842, 'actual_info_gain': 6.976017935360935, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
Updating candidate pool: Adding 100 common words...
Evaluating 217 potential guesses from 118 remaining candidates...
Top 5 guesses: [('CHILD', '3.366'), ('MEDIA', '3.260'), ('DOING', '3.245'), ('COULD', '3.210'), ('MONEY', '3.177')]
Top entropy choice: 𝘾𝙃𝙄𝙇𝘿 with entropy: 3.3661
Ended up choosing COMMON word: 𝘾𝙃𝙄𝙇𝘿 with entropy: 3.3661

Guess: 𝘾𝙃𝙄𝙇𝘿, Feedback: ⬜⬜⬜⬜⬜
Actual Info Gain: 1.3908 bits
Posterior entropy: 5.491853096329675
entropy_info: {'prior_entropy': 6.882643049361842, 'posterior_entropy': 5.491853096329675, 'actual_info_gain': 1.3907899530321668, 'expected_info_gain': 3.366066530566613}
----------
The bot is making a guess...
Evaluating 45 potential guesses from 45 remaining candidates...
Top 5 guesses: [('MARAY', '3.431'), ('MARRA', '3.367'), ('MARKA', '3.363'), ('KARMA', '3.304'), ('MARAN', '3.288')]
Top entropy choice: 𝙈𝘼𝙍𝘼𝙔 with entropy: 3.4309
Ended up choosing COMMON word: 𝙆𝘼𝙍𝙈𝘼 with entropy: 3.3042

Guess: 𝙆𝘼𝙍𝙈𝘼, Feedback: ⬜🟩🟩⬜⬜
Actual Info Gain: 1.9069 bits
Posterior entropy: 3.584962500721156
entropy_info: {'prior_entropy': 5.491853096329675, 'posterior_entropy': 3.584962500721156, 'actual_info_gain': 1.9068905956085187, 'expected_info_gain': 3.3041759413546874}
----------
The bot is making a guess...
Evaluating 12 potential guesses from 12 remaining candidates...
Top 5 guesses: [('BARRO', '3.022'), ('BARRY', '3.022'), ('BARFY', '2.855'), ('GARBO', '2.855'), ('BARNY', '2.792')]
Top entropy choice: 𝘽𝘼𝙍𝙍𝙊 with entropy: 3.0221
Ended up choosing COMMON word: 𝘽𝘼𝙍𝙍𝙔 with entropy: 3.0221

Guess: 𝘽𝘼𝙍𝙍𝙔, Feedback: 🟩🟩🟩⬜⬜
Actual Info Gain: 3.5850 bits
Posterior entropy: 0.0
entropy_info: {'prior_entropy': 3.584962500721156, 'posterior_entropy': 0.0, 'actual_info_gain': 3.584962500721156, 'expected_info_gain': 3.0220552088742005}
----------
The bot is making a guess...
Evaluating 1 potential guesses from 1 remaining candidates...
Top 5 guesses: [('BARON', '0.000')]
Top entropy choice: 𝘽𝘼𝙍𝙊𝙉 with entropy: 0.0000
Ended up choosing COMMON word: 𝘽𝘼𝙍𝙊𝙉 with entropy: 0.0000
You won! Amount of guesses: 5

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 6.976 bits, Posterior Entropy: 6.883, 
Guess: 𝘾𝙃𝙄𝙇𝘿, Feedback: ⬜⬜⬜⬜⬜, Prior Entropy: 6.883, Expected Info Gain: 3.366 bits, Actual Info Gain: 1.391 bits, Posterior Entropy: 5.492, 
Guess: 𝙆𝘼𝙍𝙈𝘼, Feedback: ⬜🟩🟩⬜⬜, Prior Entropy: 5.492, Expected Info Gain: 3.304 bits, Actual Info Gain: 1.907 bits, Posterior Entropy: 3.585, 
Guess: 𝘽𝘼𝙍𝙍𝙔, Feedback: 🟩🟩🟩⬜⬜, Prior Entropy: 3.585, Expected Info Gain: 3.022 bits, Actual Info Gain: 3.585 bits, Posterior Entropy: 0.000, 
Guess: 𝘽𝘼𝙍𝙊𝙉, Feedback: 🟩🟩🟩🟩🟩
===================================

Testing bot class: CachedEntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: NonGreedyCachedEntropyWordleBot
___ Testing word: 𝘽𝘼𝙍𝙊𝙉 ___

Loading letter frequencies...
Loaded letter frequency cache with 26 letters
The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜⬜
Actual Info Gain: 6.9760 bits
Posterior entropy: 6.882643049361842
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 6.882643049361842, 'actual_info_gain': 6.976017935360935, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
THe possible candidates are: ['AARGH', 'BARBY', 'BARCA', 'BARDO', 'BARDY', 'BARFI', 'BARFY', 'BARIC', 'BARKY', 'BARMY', 'BARNY', 'BARON', 'BARRA', 'BARRO', 'BARRY', 'CARAP', 'CARBO', 'CARBY', 'CARDI', 'CARDY', 'CARGO', 'CARNY', 'CAROB', 'CAROL', 'CAROM', 'CARON', 'CARPI', 'CARRY', 'CARVY', 'DARAF', 'DARCY', 'DARGA', 'DARIC', 'DARKY', 'DARZI', 'FARAD', 'FARCI', 'FARCY', 'FARRO', 'GARAM', 'GARBA', 'GARBO', 'GARDA', 'GARNI', 'GARRI', 'GARUM', 'HARAM', 'HARDY', 'HARIM', 'HARPY', 'HARRY', 'JARUL', 'KARAI', 'KARMA', 'KAROO', 'KARRI', 'KARZY', 'LARCH', 'LARDY', 'LARGA', 'LARGO', 'LARKY', 'LARUM', 'LARVA', 'MARAH', 'MARAL', 'MARAN', 'MARAY', 'MARCH', 'MARDY', 'MARGA', 'MARGO', 'MARIA', 'MARID', 'MARIL', 'MARKA', 'MARLY', 'MARMA', 'MARON', 'MAROR', 'MARRA', 'MARRI', 'MARRY', 'MARUA', 'MARVY', 'NARCO', 'NARIC', 'NARKY', 'NAROD', 'NARRA', 'PARCH', 'PARDI', 'PARDY', 'PARGO', 'PARID', 'PARKA', 'PARKI', 'PARKY', 'PARLY', 'PARMA', 'PARMO', 'PAROL', 'PARRA', 'PARRY', 'PARVO', 'VARAN', 'VARDA', 'VARDO', 'VARDY', 'VARIA', 'VARIX', 'VARNA', 'WARBY', 'YARAK', 'YARCO', 'YARFA', 'YARRA', 'ZARDA']
118 candidate words remaining.
Top 10 guesses: [('MINCY', '3.994'), ('MOLDY', '3.993'), ('COMBY', '3.944'), ('MYOID', '3.913'), ('CYMOL', '3.890'), ('COMBI', '3.882'), ('MOCKY', '3.855'), ('MICKY', '3.849'), ('DIMBO', '3.844'), ('MIDGY', '3.812')]
Top entropy choice: 𝙈𝙄𝙉𝘾𝙔 with entropy: 3.9942
Guess count low, choosing the word with highest entropy: 𝙈𝙄𝙉𝘾𝙔 with entropy: 3.9942

Guess: 𝙈𝙄𝙉𝘾𝙔, Feedback: ⬜⬜🟨⬜⬜
Actual Info Gain: 4.5607 bits
Posterior entropy: 2.321928094887362
entropy_info: {'prior_entropy': 6.882643049361842, 'posterior_entropy': 2.321928094887362, 'actual_info_gain': 4.560714954474479, 'expected_info_gain': 3.994197821504514}
----------
The bot is making a guess...
THe possible candidates are: ['BARON', 'NAROD', 'NARRA', 'VARAN', 'VARNA']
5 candidate words remaining.
Top 10 guesses: [('ABORN', '2.322'), ('ABUNA', '2.322'), ('ABURA', '2.322'), ('ACORN', '2.322'), ('ADDRA', '2.322'), ('ADORN', '2.322'), ('AVIAN', '2.322'), ('AVION', '2.322'), ('AWARN', '2.322'), ('BAJRA', '2.322')]
Top entropy choice: 𝘼𝘽𝙊𝙍𝙉 with entropy: 2.3219
Using common exploratory word: 𝘼𝘾𝙊𝙍𝙉 with entropy: 2.3219

Guess: 𝘼𝘾𝙊𝙍𝙉, Feedback: 🟨⬜🟨🟨🟩
Actual Info Gain: 2.3219 bits
Posterior entropy: 0.0
entropy_info: {'prior_entropy': 2.321928094887362, 'posterior_entropy': 0.0, 'actual_info_gain': 2.321928094887362, 'expected_info_gain': 3.994197821504514}
----------
The bot is making a guess...
THe possible candidates are: ['BARON']
1 candidate words remaining.
Top 10 guesses: [('BARON', '0.000')]
Top entropy choice: 𝘽𝘼𝙍𝙊𝙉 with entropy: 0.0000
Few candidates left, going through them all to pick a common word...
Using common word: 𝘽𝘼𝙍𝙊𝙉 with entropy: 0.0000
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜⬜, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 6.976 bits, Posterior Entropy: 6.883, 
Guess: 𝙈𝙄𝙉𝘾𝙔, Feedback: ⬜⬜🟨⬜⬜, Prior Entropy: 6.883, Expected Info Gain: 3.994 bits, Actual Info Gain: 4.561 bits, Posterior Entropy: 2.322, 
Guess: 𝘼𝘾𝙊𝙍𝙉, Feedback: 🟨⬜🟨🟨🟩, Prior Entropy: 2.322, Expected Info Gain: 3.994 bits, Actual Info Gain: 2.322 bits, Posterior Entropy: 0.000, 
Guess: 𝘽𝘼𝙍𝙊𝙉, Feedback: 🟩🟩🟩🟩🟩
===================================

Testing bot class: NonGreedyCachedEntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
