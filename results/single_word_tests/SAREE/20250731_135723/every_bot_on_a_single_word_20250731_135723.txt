Testing bot: WordleBot
___ Testing word: ğ™ğ˜¼ğ™ğ™€ğ™€ ___

First Starting word: 'TARES' (Best starting word for catching common words)
Guess: ğ™ğ˜¼ğ™ğ™€ğ™, Feedback: â¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨
entropy_info: None
----------
The bot originally chose: SARED 
The top ten guesses and scores: [('SARED', 10), ('SAREE', 9)]
The bot finally chose: SAREE 
You won! Amount of guesses: 2

===================================
History:
Guess: ğ™ğ˜¼ğ™ğ™€ğ™, Feedback: â¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨
Guess: ğ™ğ˜¼ğ™ğ™€ğ™€, Feedback: ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©
===================================

Testing bot class: WordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: EntropyWordleBot
___ Testing word: ğ™ğ˜¼ğ™ğ™€ğ™€ ___


The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: ğ™ğ˜¼ğ™ğ™€ğ™, Feedback: â¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨
Actual Info Gain: 12.8587 bits
Posterior entropy: 1.0
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 1.0, 'actual_info_gain': 12.858660984722777, 'expected_info_gain': 6.15937645579268}
----------

The bot is making a guess...
Initial guess by the bot: SARED with entropy: 1.0000
Bot chose: SAREE with entropy: 1.0000
Top ten guesses: [('SARED', 1.0), ('SAREE', 1.0)]
You won! Amount of guesses: 2

===================================
History:
Guess: ğ™ğ˜¼ğ™ğ™€ğ™, Feedback: â¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 12.859 bits, Posterior Entropy: 1.000, 
Guess: ğ™ğ˜¼ğ™ğ™€ğ™€, Feedback: ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©
===================================

Testing bot class: EntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: FastEntropyWordleBot
___ Testing word: ğ™ğ˜¼ğ™ğ™€ğ™€ ___


The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: ğ™ğ˜¼ğ™ğ™€ğ™, Feedback: â¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨
Actual Info Gain: 12.8587 bits
Posterior entropy: 1.0
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 1.0, 'actual_info_gain': 12.858660984722777, 'expected_info_gain': 6.15937645579268}
----------

The bot is making a guess...
Initial guess by the bot: SARED with entropy: 1.0000
Bot chose: SAREE with entropy: 1.0000
Top ten guesses: [('SARED', 1.0), ('SAREE', 1.0)]
You won! Amount of guesses: 2

===================================
History:
Guess: ğ™ğ˜¼ğ™ğ™€ğ™, Feedback: â¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 12.859 bits, Posterior Entropy: 1.000, 
Guess: ğ™ğ˜¼ğ™ğ™€ğ™€, Feedback: ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©
===================================

Testing bot class: FastEntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: CachedEntropyWordleBot
___ Testing word: ğ™ğ˜¼ğ™ğ™€ğ™€ ___

Loading letter frequencies...
Loaded letter frequency cache with 26 letters
The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: ğ™ğ˜¼ğ™ğ™€ğ™, Feedback: â¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨
Actual Info Gain: 12.8587 bits
Posterior entropy: 1.0
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 1.0, 'actual_info_gain': 12.858660984722777, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
Evaluating 2 potential guesses from 2 remaining candidates...
Top 5 guesses: [('SARED', '1.000'), ('SAREE', '1.000')]
Top entropy choice: ğ™ğ˜¼ğ™ğ™€ğ˜¿ with entropy: 1.0000
Ended up choosing COMMON word: ğ™ğ˜¼ğ™ğ™€ğ™€ with entropy: 1.0000
You won! Amount of guesses: 2

===================================
History:
Guess: ğ™ğ˜¼ğ™ğ™€ğ™, Feedback: â¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 12.859 bits, Posterior Entropy: 1.000, 
Guess: ğ™ğ˜¼ğ™ğ™€ğ™€, Feedback: ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©
===================================

Testing bot class: CachedEntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: NonGreedyCachedEntropyWordleBot
___ Testing word: ğ™ğ˜¼ğ™ğ™€ğ™€ ___

Loading letter frequencies...
Loaded letter frequency cache with 26 letters
The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: ğ™ğ˜¼ğ™ğ™€ğ™, Feedback: â¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨
Actual Info Gain: 12.8587 bits
Posterior entropy: 1.0
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 1.0, 'actual_info_gain': 12.858660984722777, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
THe possible candidates are: ['SARED', 'SAREE']
2 candidate words remaining.
Top 10 guesses: [('SARED', '1.000'), ('SAREE', '1.000')]
Top entropy choice: ğ™ğ˜¼ğ™ğ™€ğ˜¿ with entropy: 1.0000
Guess count low, choosing the word with highest entropy: ğ™ğ˜¼ğ™ğ™€ğ˜¿ with entropy: 1.0000

Guess: ğ™ğ˜¼ğ™ğ™€ğ˜¿, Feedback: ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©â¬œ
Actual Info Gain: 1.0000 bits
Posterior entropy: 0.0
entropy_info: {'prior_entropy': 1.0, 'posterior_entropy': 0.0, 'actual_info_gain': 1.0, 'expected_info_gain': 1.0}
----------
The bot is making a guess...
THe possible candidates are: ['SAREE']
1 candidate words remaining.
Top 10 guesses: [('SAREE', '0.000')]
Top entropy choice: ğ™ğ˜¼ğ™ğ™€ğ™€ with entropy: 0.0000
Few candidates left, going through them all to pick a common word...
Using common word: ğ™ğ˜¼ğ™ğ™€ğ™€ with entropy: 0.0000
You won! Amount of guesses: 3

===================================
History:
Guess: ğ™ğ˜¼ğ™ğ™€ğ™, Feedback: â¬œğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ¨, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 12.859 bits, Posterior Entropy: 1.000, 
Guess: ğ™ğ˜¼ğ™ğ™€ğ˜¿, Feedback: ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©â¬œ, Prior Entropy: 1.000, Expected Info Gain: 1.000 bits, Actual Info Gain: 1.000 bits, Posterior Entropy: 0.000, 
Guess: ğ™ğ˜¼ğ™ğ™€ğ™€, Feedback: ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©ğŸŸ©
===================================

Testing bot class: NonGreedyCachedEntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
