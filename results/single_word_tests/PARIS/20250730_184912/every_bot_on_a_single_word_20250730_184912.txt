Testing bot: WordleBot
___ Testing word: 𝙋𝘼𝙍𝙄𝙎 ___

First Starting word: 'TARES' (Best starting word for catching common words)
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜🟩
entropy_info: None
----------
The bot originally chose: DARKS 
The top ten guesses and scores: [('DARKS', 307), ('MARKS', 304), ('PARKS', 304), ('KARNS', 303), ('MARDS', 303), ('NARKS', 303), ('PARDS', 303), ('BARKS', 302), ('DARNS', 302), ('NARDS', 302)]
The bot finally chose: DARKS 
Guess: 𝘿𝘼𝙍𝙆𝙎, Feedback: ⬜🟩🟩⬜🟩
entropy_info: None
----------
The bot originally chose: PARMS 
The top ten guesses and scores: [('PARMS', 193), ('BARMS', 190), ('BARPS', 190), ('CARPS', 189), ('MARCS', 189), ('MARLS', 189), ('PARCS', 189), ('BARNS', 187), ('FARMS', 187), ('PARIS', 187)]
The bot finally chose: PARIS 
You won! Amount of guesses: 3

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜🟩
Guess: 𝘿𝘼𝙍𝙆𝙎, Feedback: ⬜🟩🟩⬜🟩
Guess: 𝙋𝘼𝙍𝙄𝙎, Feedback: 🟩🟩🟩🟩🟩
===================================

Testing bot class: WordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: EntropyWordleBot
___ Testing word: 𝙋𝘼𝙍𝙄𝙎 ___


The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜🟩
Actual Info Gain: 7.4324 bits
Posterior entropy: 6.426264754702098
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 6.426264754702098, 'actual_info_gain': 7.432396230020679, 'expected_info_gain': 6.15937645579268}
----------

The bot is making a guess...
Initial guess by the bot: DARKS with entropy: 1.7041
Bot chose: DARKS with entropy: 1.7041
Top ten guesses: [('DARKS', 1.704127822035885), ('MARDS', 1.6329701411062292), ('DARNS', 1.6327379687124135), ('NARDS', 1.6327379687124135), ('PARDS', 1.63016113040639), ('KARNS', 1.5984877816483798), ('MARKS', 1.5849288866318443), ('PARKS', 1.5821198759320052), ('NARKS', 1.5713798883342303), ('DARBS', 1.5558926891874658)]

Guess: 𝘿𝘼𝙍𝙆𝙎, Feedback: ⬜🟩🟩⬜🟩
Actual Info Gain: 0.6983 bits
Posterior entropy: 5.727920454563199
entropy_info: {'prior_entropy': 6.426264754702098, 'posterior_entropy': 5.727920454563199, 'actual_info_gain': 0.6983443001388991, 'expected_info_gain': 1.704127822035885}
----------

The bot is making a guess...
Initial guess by the bot: PARMS with entropy: 1.8274
Bot chose: PARMS with entropy: 1.8274
Top ten guesses: [('PARMS', 1.8273722290311134), ('BARPS', 1.6619001895799745), ('CARPS', 1.657600821990368), ('PARCS', 1.657600821990368), ('MARLS', 1.6564191696657609), ('BARMS', 1.6564191696657606), ('MARCS', 1.6402917550945657), ('BARNS', 1.5417093223549938), ('LARNS', 1.5255819077837987), ('FARMS', 1.5201008878695852)]

Guess: 𝙋𝘼𝙍𝙈𝙎, Feedback: 🟩🟩🟩⬜🟩
Actual Info Gain: 3.4060 bits
Posterior entropy: 2.321928094887362
entropy_info: {'prior_entropy': 5.727920454563199, 'posterior_entropy': 2.321928094887362, 'actual_info_gain': 3.4059923596758366, 'expected_info_gain': 1.8273722290311134}
----------

The bot is making a guess...
Initial guess by the bot: PARAS with entropy: 0.7219
Bot chose: PARIS with entropy: 0.7219
Top ten guesses: [('PARAS', 0.7219280948873623), ('PARCS', 0.7219280948873623), ('PARIS', 0.7219280948873623), ('PARPS', 0.7219280948873623), ('PARRS', 0.7219280948873623)]
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜🟩, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 7.432 bits, Posterior Entropy: 6.426, 
Guess: 𝘿𝘼𝙍𝙆𝙎, Feedback: ⬜🟩🟩⬜🟩, Prior Entropy: 6.426, Expected Info Gain: 1.704 bits, Actual Info Gain: 0.698 bits, Posterior Entropy: 5.728, 
Guess: 𝙋𝘼𝙍𝙈𝙎, Feedback: 🟩🟩🟩⬜🟩, Prior Entropy: 5.728, Expected Info Gain: 1.827 bits, Actual Info Gain: 3.406 bits, Posterior Entropy: 2.322, 
Guess: 𝙋𝘼𝙍𝙄𝙎, Feedback: 🟩🟩🟩🟩🟩
===================================

Testing bot class: EntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: FastEntropyWordleBot
___ Testing word: 𝙋𝘼𝙍𝙄𝙎 ___


The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜🟩
Actual Info Gain: 7.4324 bits
Posterior entropy: 6.426264754702098
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 6.426264754702098, 'actual_info_gain': 7.432396230020679, 'expected_info_gain': 6.15937645579268}
----------

The bot is making a guess...
Initial guess by the bot: DARKS with entropy: 1.7041
Bot chose: DARKS with entropy: 1.7041
Top ten guesses: [('DARKS', 1.704127822035885), ('MARDS', 1.6329701411062292), ('DARNS', 1.6327379687124135), ('NARDS', 1.6327379687124135), ('PARDS', 1.63016113040639), ('KARNS', 1.5984877816483798), ('MARKS', 1.5849288866318443), ('PARKS', 1.5821198759320052), ('NARKS', 1.5713798883342303), ('DARBS', 1.5558926891874658)]

Guess: 𝘿𝘼𝙍𝙆𝙎, Feedback: ⬜🟩🟩⬜🟩
Actual Info Gain: 0.6983 bits
Posterior entropy: 5.727920454563199
entropy_info: {'prior_entropy': 6.426264754702098, 'posterior_entropy': 5.727920454563199, 'actual_info_gain': 0.6983443001388991, 'expected_info_gain': 1.704127822035885}
----------

The bot is making a guess...
Initial guess by the bot: PARMS with entropy: 1.8274
Bot chose: PARMS with entropy: 1.8274
Top ten guesses: [('PARMS', 1.8273722290311134), ('BARPS', 1.6619001895799745), ('CARPS', 1.657600821990368), ('PARCS', 1.657600821990368), ('MARLS', 1.6564191696657609), ('BARMS', 1.6564191696657606), ('MARCS', 1.6402917550945657), ('BARNS', 1.5417093223549938), ('LARNS', 1.5255819077837987), ('FARMS', 1.5201008878695852)]

Guess: 𝙋𝘼𝙍𝙈𝙎, Feedback: 🟩🟩🟩⬜🟩
Actual Info Gain: 3.4060 bits
Posterior entropy: 2.321928094887362
entropy_info: {'prior_entropy': 5.727920454563199, 'posterior_entropy': 2.321928094887362, 'actual_info_gain': 3.4059923596758366, 'expected_info_gain': 1.8273722290311134}
----------

The bot is making a guess...
Initial guess by the bot: PARAS with entropy: 0.7219
Bot chose: PARIS with entropy: 0.7219
Top ten guesses: [('PARAS', 0.7219280948873623), ('PARCS', 0.7219280948873623), ('PARIS', 0.7219280948873623), ('PARPS', 0.7219280948873623), ('PARRS', 0.7219280948873623)]
You won! Amount of guesses: 4

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜🟩, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 7.432 bits, Posterior Entropy: 6.426, 
Guess: 𝘿𝘼𝙍𝙆𝙎, Feedback: ⬜🟩🟩⬜🟩, Prior Entropy: 6.426, Expected Info Gain: 1.704 bits, Actual Info Gain: 0.698 bits, Posterior Entropy: 5.728, 
Guess: 𝙋𝘼𝙍𝙈𝙎, Feedback: 🟩🟩🟩⬜🟩, Prior Entropy: 5.728, Expected Info Gain: 1.827 bits, Actual Info Gain: 3.406 bits, Posterior Entropy: 2.322, 
Guess: 𝙋𝘼𝙍𝙄𝙎, Feedback: 🟩🟩🟩🟩🟩
===================================

Testing bot class: FastEntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: CachedEntropyWordleBot
___ Testing word: 𝙋𝘼𝙍𝙄𝙎 ___

Loading letter frequencies...
Loaded letter frequency cache with 26 letters
The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜🟩
Actual Info Gain: 7.4324 bits
Posterior entropy: 6.426264754702098
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 6.426264754702098, 'actual_info_gain': 7.432396230020679, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
Updating candidate pool: Adding 100 common words...
Evaluating 186 potential guesses from 86 remaining candidates...
Top 5 guesses: [('CHILD', '2.722'), ('DOING', '2.505'), ('BLACK', '2.457'), ('COULD', '2.359'), ('FINAL', '2.306')]
Top entropy choice: 𝘾𝙃𝙄𝙇𝘿 with entropy: 2.7217
Ended up choosing COMMON word: 𝘾𝙃𝙄𝙇𝘿 with entropy: 2.7217

Guess: 𝘾𝙃𝙄𝙇𝘿, Feedback: ⬜⬜🟨⬜⬜
Actual Info Gain: 4.1043 bits
Posterior entropy: 2.321928094887362
entropy_info: {'prior_entropy': 6.426264754702098, 'posterior_entropy': 2.321928094887362, 'actual_info_gain': 4.104336659814736, 'expected_info_gain': 2.721724455921137}
----------
The bot is making a guess...
Evaluating 5 potential guesses from 5 remaining candidates...
Top 5 guesses: [('GARIS', '0.722'), ('NARIS', '0.722'), ('PARIS', '0.722'), ('SARIS', '0.722'), ('ZARIS', '0.722')]
Top entropy choice: 𝙂𝘼𝙍𝙄𝙎 with entropy: 0.7219
Ended up choosing COMMON word: 𝙋𝘼𝙍𝙄𝙎 with entropy: 0.7219
You won! Amount of guesses: 3

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜🟩, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 7.432 bits, Posterior Entropy: 6.426, 
Guess: 𝘾𝙃𝙄𝙇𝘿, Feedback: ⬜⬜🟨⬜⬜, Prior Entropy: 6.426, Expected Info Gain: 2.722 bits, Actual Info Gain: 4.104 bits, Posterior Entropy: 2.322, 
Guess: 𝙋𝘼𝙍𝙄𝙎, Feedback: 🟩🟩🟩🟩🟩
===================================

Testing bot class: CachedEntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
Testing bot: NonGreedyCachedEntropyWordleBot
___ Testing word: 𝙋𝘼𝙍𝙄𝙎 ___

Loading letter frequencies...
Loaded letter frequency cache with 26 letters
The bot is making a guess...
First Starting word: TARES (Best starting word for catching common words)

Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜🟩
Actual Info Gain: 7.4324 bits
Posterior entropy: 6.426264754702098
entropy_info: {'prior_entropy': 13.858660984722777, 'posterior_entropy': 6.426264754702098, 'actual_info_gain': 7.432396230020679, 'expected_info_gain': 6.15937645579268}
----------
The bot is making a guess...
THe possible candidates are: ['BARBS', 'BARDS', 'BARFS', 'BARKS', 'BARMS', 'BARNS', 'BARPS', 'CARBS', 'CARDS', 'CARKS', 'CARLS', 'CARNS', 'CARPS', 'CARRS', 'DARBS', 'DARGS', 'DARIS', 'DARKS', 'DARLS', 'DARNS', 'FARDS', 'FARLS', 'FARMS', 'FAROS', 'GARBS', 'GARIS', 'GARMS', 'HARDS', 'HARKS', 'HARLS', 'HARMS', 'HARNS', 'HAROS', 'HARPS', 'JARKS', 'JARLS', 'JARPS', 'KARAS', 'KARKS', 'KARNS', 'KAROS', 'LARDS', 'LARFS', 'LARIS', 'LARKS', 'LARNS', 'MARAS', 'MARCS', 'MARDS', 'MARGS', 'MARKS', 'MARLS', 'MARMS', 'NARAS', 'NARCS', 'NARDS', 'NARIS', 'NARKS', 'PARAS', 'PARCS', 'PARDS', 'PARIS', 'PARKS', 'PARMS', 'PARPS', 'PARRS', 'RARKS', 'SARDS', 'SARIS', 'SARKS', 'SAROS', 'SARUS', 'VARAS', 'VARUS', 'WARBS', 'WARDS', 'WARKS', 'WARMS', 'WARNS', 'WARPS', 'YARDS', 'YARKS', 'YARNS', 'YARRS', 'ZARFS', 'ZARIS']
86 candidate words remaining.
Top 10 guesses: [('PLINK', '3.008'), ('BLIND', '2.996'), ('BLINK', '2.947'), ('KINDY', '2.915'), ('CLINK', '2.910'), ('DINKY', '2.891'), ('PLONK', '2.891'), ('BLOND', '2.851'), ('BLIMP', '2.834'), ('CLONK', '2.810')]
Top entropy choice: 𝙋𝙇𝙄𝙉𝙆 with entropy: 3.0082
Guess count low, choosing the word with highest entropy: 𝙋𝙇𝙄𝙉𝙆 with entropy: 3.0082

Guess: 𝙋𝙇𝙄𝙉𝙆, Feedback: 🟩⬜🟨⬜⬜
Actual Info Gain: 6.4263 bits
Posterior entropy: 0.0
entropy_info: {'prior_entropy': 6.426264754702098, 'posterior_entropy': 0.0, 'actual_info_gain': 6.426264754702098, 'expected_info_gain': 3.0081856819123614}
----------
The bot is making a guess...
THe possible candidates are: ['PARIS']
1 candidate words remaining.
Top 10 guesses: [('PARIS', '0.000')]
Top entropy choice: 𝙋𝘼𝙍𝙄𝙎 with entropy: 0.0000
Few candidates left, going through them all to pick a common word...
Using common word: 𝙋𝘼𝙍𝙄𝙎 with entropy: 0.0000
You won! Amount of guesses: 3

===================================
History:
Guess: 𝙏𝘼𝙍𝙀𝙎, Feedback: ⬜🟩🟩⬜🟩, Prior Entropy: 13.859, Expected Info Gain: 6.159 bits, Actual Info Gain: 7.432 bits, Posterior Entropy: 6.426, 
Guess: 𝙋𝙇𝙄𝙉𝙆, Feedback: 🟩⬜🟨⬜⬜, Prior Entropy: 6.426, Expected Info Gain: 3.008 bits, Actual Info Gain: 6.426 bits, Posterior Entropy: 0.000, 
Guess: 𝙋𝘼𝙍𝙄𝙎, Feedback: 🟩🟩🟩🟩🟩
===================================

Testing bot class: NonGreedyCachedEntropyWordleBot complete.

----------------------------------------------------------------------------------------------------
